{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439ae540",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ab601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Snaju003/Final-year-project.git\n",
    "%cd Final-year-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ac89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0858ed",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caae412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/content/Final-year-project')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import project modules\n",
    "from src.models import build_all_models\n",
    "from src.inference import EnsembleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027016ae",
   "metadata": {},
   "source": [
    "## 3. Load Model and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ensemble model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EnsembleModel().to(device)\n",
    "\n",
    "# Load pre-trained weights if available\n",
    "model_path = 'models/ensemble/ensemble_final.pth'\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(f\"✅ Model loaded from {model_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ Model weights not found. Using random initialization.\")\n",
    "\n",
    "model.eval()\n",
    "print(f\"✅ Model ready on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4269600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on a single image\n",
    "def predict_image(image_path, model, device):\n",
    "    \"\"\"\n",
    "    Predict deepfake probability for a single image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "        model: Ensemble model\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        deepfake_probability: Float between 0 and 1\n",
    "    \"\"\"\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # Image preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    return output.item()\n",
    "\n",
    "# Example usage (uncomment when you have an image)\n",
    "# image_path = 'your_image.jpg'\n",
    "# prob = predict_image(image_path, model, device)\n",
    "# print(f\"Deepfake probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302e1ad",
   "metadata": {},
   "source": [
    "## 4. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e16670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(image_dir, model, device):\n",
    "    \"\"\"\n",
    "    Predict on multiple images in a directory\n",
    "    \"\"\"\n",
    "    from torchvision import transforms\n",
    "    from pathlib import Path\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    results = {}\n",
    "    image_paths = list(Path(image_dir).glob('*.jpg')) + list(Path(image_dir).glob('*.png'))\n",
    "    \n",
    "    for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "            \n",
    "            results[image_path.name] = output.item()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "# results = batch_predict('path/to/images', model, device)\n",
    "# for img_name, prob in results.items():\n",
    "#     print(f\"{img_name}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df78b42",
   "metadata": {},
   "source": [
    "## 5. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04798658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results to local machine\n",
    "from google.colab import files\n",
    "\n",
    "# Save results to a file\n",
    "import json\n",
    "# results_path = 'results.json'\n",
    "# with open(results_path, 'w') as f:\n",
    "#     json.dump(results, f, indent=2)\n",
    "\n",
    "# Download\n",
    "# files.download(results_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
