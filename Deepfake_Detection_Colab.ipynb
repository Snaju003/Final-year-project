{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d2f2a7",
   "metadata": {},
   "source": [
    "# Deepfake Detection - Google Colab Setup\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT: Setup Instructions\n",
    "\n",
    "This notebook supports multiple setup methods to handle different scenarios.\n",
    "\n",
    "### **Choose Your Setup Method:**\n",
    "\n",
    "1. **If repository is PUBLIC on GitHub:**\n",
    "   - Just run the cells in order\n",
    "   - The notebook will auto-clone the repo\n",
    "\n",
    "2. **If repository is PRIVATE or Network Issues:**\n",
    "   - Upload the entire `Final-year-project` folder to **Google Drive/MyDrive/**\n",
    "   - Run the cells - notebook will detect and use it\n",
    "   - See cell below for details\n",
    "\n",
    "3. **Just Upload Project Files:**\n",
    "   - Create a ZIP of your project\n",
    "   - Upload to Colab directly or to Drive\n",
    "   - Extract and run setup\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc038869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment and connection status\n",
    "print(\"=\" * 60)\n",
    "print(\"COLAB ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    print(\"‚ùå Not running in Google Colab\")\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Check internet connection\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run(['ping', '-c', '1', 'github.com'], \n",
    "                          capture_output=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Internet connection available\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Cannot reach GitHub (network issue)\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Network check failed\")\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è GPU not available (using CPU)\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è PyTorch not installed yet\")\n",
    "\n",
    "print(\"\\nüìã Next steps:\")\n",
    "print(\"1. If GitHub clone fails ‚Üí Upload project to Google Drive/MyDrive/\")\n",
    "print(\"2. Extract uploaded ZIP if using that method\")\n",
    "print(\"3. Run the 'Setup Environment' cell below\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ae540",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ab601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Choose method based on your situation\n",
    "\n",
    "# METHOD 1: Clone from GitHub (requires public repo)\n",
    "try:\n",
    "    !git clone https://github.com/Snaju003/Final-year-project.git\n",
    "    %cd Final-year-project\n",
    "    print(\"‚úÖ Repository cloned successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è GitHub clone failed: {e}\")\n",
    "    print(\"Using METHOD 2: Upload from Google Drive instead\")\n",
    "\n",
    "# METHOD 2: If GitHub doesn't work, mount Google Drive and use files from there\n",
    "import os\n",
    "if not os.path.exists('Final-year-project'):\n",
    "    print(\"\\nüìÅ Mounting Google Drive for file access...\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    \n",
    "    # Copy project from Google Drive if it exists\n",
    "    import shutil\n",
    "    if os.path.exists('/content/drive/MyDrive/Final-year-project'):\n",
    "        shutil.copytree('/content/drive/MyDrive/Final-year-project', '/content/Final-year-project')\n",
    "        %cd /content/Final-year-project\n",
    "        print(\"‚úÖ Project copied from Google Drive\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Project not found in Google Drive\")\n",
    "        print(\"üìã To fix: Upload the 'Final-year-project' folder to Google Drive/MyDrive/\")\n",
    "\n",
    "# Verify we're in the right directory\n",
    "import os\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "print(f\"Files: {os.listdir('.')[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ac89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies from requirements.txt\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Try to install from requirements.txt\n",
    "if os.path.exists('requirements.txt'):\n",
    "    print(\"üì¶ Installing from requirements.txt...\")\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-r', 'requirements.txt'], \n",
    "                   capture_output=True)\n",
    "    print(\"‚úÖ Dependencies installed\")\n",
    "else:\n",
    "    # Fallback: install key packages individually\n",
    "    print(\"‚ö†Ô∏è requirements.txt not found. Installing essential packages...\")\n",
    "    packages = [\n",
    "        'torch==2.0.1',\n",
    "        'torchvision==0.15.2',\n",
    "        'timm==0.9.12',\n",
    "        'facenet-pytorch==2.5.3',\n",
    "        'opencv-python==4.8.1.78',\n",
    "        'tqdm==4.65.0',\n",
    "        'pytorch-gradcam==0.2.1',\n",
    "        'scikit-image==0.21.0',\n",
    "        'scikit-learn==1.3.2',\n",
    "        'Pillow==10.0.1',\n",
    "    ]\n",
    "    for pkg in packages:\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', pkg],\n",
    "                       capture_output=True)\n",
    "    print(\"‚úÖ Essential packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0858ed",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caae412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/content/Final-year-project')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import project modules\n",
    "from src.models import build_all_models\n",
    "from src.inference import EnsembleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027016ae",
   "metadata": {},
   "source": [
    "## 3. Load Model and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ensemble model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EnsembleModel().to(device)\n",
    "\n",
    "# Load pre-trained weights if available\n",
    "model_path = 'models/ensemble/ensemble_final.pth'\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(f\"‚úÖ Model loaded from {model_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Model weights not found. Using random initialization.\")\n",
    "\n",
    "model.eval()\n",
    "print(f\"‚úÖ Model ready on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4269600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on a single image\n",
    "def predict_image(image_path, model, device):\n",
    "    \"\"\"\n",
    "    Predict deepfake probability for a single image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "        model: Ensemble model\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        deepfake_probability: Float between 0 and 1\n",
    "    \"\"\"\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # Image preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    return output.item()\n",
    "\n",
    "# Example usage (uncomment when you have an image)\n",
    "# image_path = 'your_image.jpg'\n",
    "# prob = predict_image(image_path, model, device)\n",
    "# print(f\"Deepfake probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302e1ad",
   "metadata": {},
   "source": [
    "## 4. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e16670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(image_dir, model, device):\n",
    "    \"\"\"\n",
    "    Predict on multiple images in a directory\n",
    "    \"\"\"\n",
    "    from torchvision import transforms\n",
    "    from pathlib import Path\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    results = {}\n",
    "    image_paths = list(Path(image_dir).glob('*.jpg')) + list(Path(image_dir).glob('*.png'))\n",
    "    \n",
    "    for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "            \n",
    "            results[image_path.name] = output.item()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "# results = batch_predict('path/to/images', model, device)\n",
    "# for img_name, prob in results.items():\n",
    "#     print(f\"{img_name}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df78b42",
   "metadata": {},
   "source": [
    "## 5. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04798658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results to local machine\n",
    "from google.colab import files\n",
    "\n",
    "# Save results to a file\n",
    "import json\n",
    "# results_path = 'results.json'\n",
    "# with open(results_path, 'w') as f:\n",
    "#     json.dump(results, f, indent=2)\n",
    "\n",
    "# Download\n",
    "# files.download(results_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
